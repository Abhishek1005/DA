{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Twitter.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pMS5Nr112Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJLim1mk12L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "consumer_key=\"k4wnQB6Os7pmGEQdx2LRFhktd\"\n",
        "consumer_secret=\"PYmT0JmhOhi1f6qGgPBNrnkOTySFXIw0j2VbarkhFoWiAS0FJs\"\n",
        "access_token=\"841984568852926465-ariDkp2pLKt3Mm6eBN4ZOtNUI7eNx78\"\n",
        "access_token_secret=\"phEY7k7z0iIAOVZn65Is9vxVwXPe18ZRAkmvc71LWhIiL\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76F9NWXo12L3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "# Setting your access token and secret\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "# Creating the API object while passing in auth information\n",
        "api = tweepy.API(auth) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBYp84Q412L5",
        "colab_type": "code",
        "colab": {},
        "outputId": "7b39bb7d-937a-4ce9-ed92-e677a34ec496"
      },
      "source": [
        "# Using the API object to get tweets from your timeline, and storing it in a variable called public_tweets\n",
        "public_tweets = api.home_timeline()\n",
        "# foreach through all tweets pulled\n",
        "for tweet in public_tweets:\n",
        "   # printing the text stored inside the tweet object\n",
        "   print(tweet.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Always waiting #KKTrailerFromTomorrow https://t.co/JffPlXU0dL\n",
            "RT @ranjithVJoff: @ajithkumar_actr @trackerpk #‡Æ™‡Øã‡Æ©‡Æø‡ÆÜ‡Æï‡Ææ‡Æ§NKP \n",
            "#vandumuruganAjith https://t.co/H7jorOfEdj\n",
            "RT @RamnadLegend: ‡Æá‡Æ®‡Øç‡Æ§ ‡Æ™‡Æ§‡Æø‡Æµ‡ØÅ ‡Æá‡Æ™‡Øç‡Æ™‡Æ§‡Ææ‡Æ©‡Øç ‡Æ™‡ØÅ‡Æ∞‡Æø‡ÆØ‡ØÅ‡Æ§‡ØÅ. ‡Æµ‡Æø‡ÆØ‡Ææ‡Æ™‡Ææ‡Æ∞‡ÆÆ‡Øç ‡ÆÜ‡Æï‡Ææ‡ÆÆ‡Æ≤‡Øç ‡Æï‡ØÜ‡Æü‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç #‡Æ®‡Øá‡Æ∞‡Øç‡Æï‡Øä‡Æ£‡Øç‡Æü‡Æ™‡Ææ‡Æ∞‡Øç‡Æµ‡Øà ‡Æ™‡Æü‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡Æµ‡Æø‡Æ≥‡ÆÆ‡Øç‡Æ™‡Æ∞‡ÆÆ‡Øç. \n",
            "\n",
            "‡Æá‡Æ®‡Øç‡Æ§ ‡Æµ‡Æø‡Æ≥‡ÆÆ‡Øç‡Æ™‡Æ∞‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡ÆÜ‚Ä¶\n",
            "RT @ThalaSp_: AB-‡Æ®‡ØÜ‡Æï‡Æü‡Øç‡Æü‡Æø‡Æµ‡Øç ‡Æ§‡Øá‡Æµ‡Øà‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡ØÅ\n",
            "‡Æâ‡Æ±‡ØÅ‡Æ§‡Æø ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü ‡Æ§‡Æï‡Æµ‡Æ≤‡Øç\n",
            "‡Æâ‡Æ§‡Æµ‡Æø ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç üôè\n",
            "\n",
            "Patient name : Moorthi\n",
            "Age : 34\n",
            "Reason : HB low\n",
            "Blood gr‚Ä¶\n",
            "RT @Richie_ofz: ‡Æâ‡Æ£‡Øç‡ÆÆ‡Øà üòÇüòÇüòÇ https://t.co/Sj7343naeV\n",
            "üòçüòç https://t.co/6mUx1Xt8rR\n",
            "The trademark LAUGH that rules our heart!\n",
            "Which is your favourite?\n",
            "\n",
            "#Rajinikanth #Enthiran #Petta #FromOurVault https://t.co/SfY2ZyZXKa\n",
            "RT @rhevanth95: Update about #MSDhoni birthday special show tomorrow ! \n",
            "Let's celebrate TN s very own adopted son @ChennaiIPL @msdhoni \n",
            "#Fa‚Ä¶\n",
            "RT @Premgiamaren: Start music üíÉüï∫üíÉ https://t.co/P6YVENf6n1\n",
            "RT @ajithkumar_actr: ‡Æü‡Øá‡ÆØ‡Øç ‡Æµ‡Øá‡Æ£‡Ææ‡ÆÆ‡Øç‡Æü‡Ææ ‡Æü‡Øç‡Æ∞‡ØÜ‡Æ£‡Øç‡Æü‡Øç ‡Æ™‡Æ£‡Øç‡Æ£‡Æø‡Æü‡Ææ‡Æ§‡ØÄ‡Æô‡Øç‡Æïüò¢\n",
            "\n",
            "#‡Æ™‡Øã‡Æ©‡Æø‡ÆÜ‡Æï‡Ææ‡Æ§NKP\n",
            "RT @ajithkumar_actr: @askithalaV4 @kingvirat86 @AlwaysTrolls @ramk8060 @TFC_Off @Itz_Thriller @Irshad_8055 @tvaoffl @KNA_Off üòÇ‡Æï‡Øä‡Æï‡Øç‡Æï‡Æø ‡Æé‡Æ©‡Øç‡Æ© ‡Æâ‚Ä¶\n",
            "Congrats team @beemji and @tcl_collective Tamizh Hiphop is Now #Therukural!\n",
            "Watch #Kallamouni Music video from‚Ä¶ https://t.co/FQlzkZA7g1\n",
            "#TALESonBET Season Premiere kicking off tomorrow, new song ‚ÄòBrothers‚Äô by Kanye West ft. Charlie Wilson TOMORROW @BET 9/8c\n",
            "RT @news7tamil: ‡Æ§‡Øã‡Æ©‡Æø‡Æï‡Øç‡Æï‡ØÅ ‡ÆÜ‡Æ§‡Æ∞‡Æµ‡Ææ‡Æï ‡Æï‡Æ≥‡ÆÆ‡Æø‡Æ±‡Æô‡Øç‡Æï‡Æø‡ÆØ ‡Æ∞‡Æö‡Æø‡Æï‡Æ∞‡Øç‡Æï‡Æ≥‡Øç....\n",
            "\n",
            "‡Æü‡Øç‡Æµ‡Æø‡Æü‡Øç‡Æü‡Æ∞‡Æø‡Æ≤‡Øç ‡Æü‡Øç‡Æ∞‡ØÜ‡Æ£‡Øç‡Æü‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç #‡Æé‡Æ©‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç_‡Æ§‡Æ≤‡Æ§‡Øã‡Æ£‡Æø ‡Æπ‡Øá‡Æ∑‡Øç‡Æü‡Øá‡Æï‡Øç!\n",
            "\n",
            "‡Æµ‡Æø‡Æµ‡Æ∞‡ÆÆ‡Øç ‚û§ https://t.co/B5zFO6E‚Ä¶\n",
            "RT @Vijay_Fans_Mode: ‡ÆÖ‡Æü‡ØÅ‡Æ§‡Øç‡Æ§ 1M ‡Æü‡Æø‡Æµ‡Æø‡Æü‡Øç ‡Æ∞‡ØÜ‡Æü‡Æø ‡ÆÜ ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æ≤ ‡Æá‡Æ©‡Øç‡Æ©‡Øà‡Æï‡Øç‡Æï‡ØÅ..! ‡Æé‡Æô‡Øç‡Æï ‡Æ™‡Æö‡Æô‡Øç‡Æï ‡Æö‡ØÅ‡ÆÆ‡Øç‡ÆÆ‡Ææ ‡Æá‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡Ææ‡Æ≤‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Æø‡Æü‡ÆÆ‡Ææ‡Æü‡Øç‡Æü‡Æø‡Æô‡Øç‡Æï ‡Æ™‡Øã‡Æ≤.! ‡ÆÖ‡Æ™‡Øç‡Æ™‡ØÅ‡Æ±‡ÆÆ‡Øç ‡Æâ‡Æô‡Øç‡Æï ‡Æµ‡Æø‡Æ∞‡ØÅ‡Æ™‡Øç‚Ä¶\n",
            "RT @VijayTeamOnline: #BIGIL is At No. 2 in @BookMyShow's Trending Searches üî•Movie Poster Only Released For #Bigil ! KING of SOCIAL MEDIA #T‚Ä¶\n",
            "RT @kuskiThala_v3: @askithalaV4 ‡Æï‡Ææ‡Æ≤‡Øà‡Æ≤ ‡Æ∏‡Øç‡Æï‡ØÇ‡Æ≤‡Øç ‡Æ™‡Øã‡ÆØ‡Æø‡Æ∞‡ØÅ‡Æµ‡Ææ‡Æô‡Øç‡Æï‡Æ©‡ØÅ ‡Æ®‡Øà‡Æü‡Øç ‡Æü‡Øá‡Æï‡Øç ‡ÆÜ ‡Æ™‡Æô‡Øç‡Æï‡Ææ‡Æ≥‡Æø üòÇüòÇüòÇüòÇüòÇüòÇüòÇ\n",
            "#‡Æ™‡Øã‡Æ©‡Æø‡ÆÜ‡Æï‡Ææ‡Æ§NKP\n",
            "RT @TheViper_OffI: Admit it This #Dhoni had zero haters! üëåüî•\n",
            "\n",
            "#MSDhoni  #INDvBAN https://t.co/ohu2fGHaFS\n",
            "Enga antha üê¢üê¢üê¢#‡Æ™‡Øã‡Æ©‡Æø‡ÆÜ‡Æï‡Ææ‡Æ§NKP https://t.co/C6wo5A5tJF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvmBuXey12L7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AlnyxHY12L9",
        "colab_type": "code",
        "colab": {},
        "outputId": "35a0839d-1c63-4830-c990-ed2d4e9c5111"
      },
      "source": [
        "nltk.download('all')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data]    | Downloading package pros_cons to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package rte to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars\\book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars\\basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping help\\tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping models\\bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers\\averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to\n",
            "[nltk_data]    |     C:\\Users\\TEMP.CSE\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmJRcoGG12L_",
        "colab_type": "code",
        "colab": {},
        "outputId": "ef6e1fb1-c77e-49f0-97ec-f5e64be978cb"
      },
      "source": [
        "df = pd.read_csv(\"Z:/sem7/DA Lab/fifa.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-306c1942d8d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Z:/sem7/DA Lab/fifa.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CjYDLL612MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv(\"Z:/sem7/DA Lab/FIFA.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNrSr31912MC",
        "colab_type": "code",
        "colab": {},
        "outputId": "4051c69f-f5c0-411c-a10a-5c49fa7b656c"
      },
      "source": [
        "a=df[\"Tweet\"].head(10)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Only two goalkeepers have saved three penaltie...\n",
              "1    scores the winning penalty to send into the qu...\n",
              "2                             Tonight we have big game\n",
              "3    We get stronger Turn the music up now We got t...\n",
              "4    Only two goalkeepers have saved three penaltie...\n",
              "5    We re looking strong going into the knockout s...\n",
              "6    am happy for winning Especially since you know...\n",
              "7    When you see me When we feel the same feeling ...\n",
              "8    Kasper Schmeichel takes the final award of the...\n",
              "9    After Years Global Puma Ambassador LG Mobile A...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi0M-5jC12ME",
        "colab_type": "code",
        "colab": {},
        "outputId": "9db008c2-c1b0-4086-b7d5-016ce305ed61"
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Only two goalkeepers have saved three penaltie...\n",
              "1         scores the winning penalty to send into the qu...\n",
              "2                                  Tonight we have big game\n",
              "3         We get stronger Turn the music up now We got t...\n",
              "4         Only two goalkeepers have saved three penaltie...\n",
              "5         We re looking strong going into the knockout s...\n",
              "6         am happy for winning Especially since you know...\n",
              "7         When you see me When we feel the same feeling ...\n",
              "8         Kasper Schmeichel takes the final award of the...\n",
              "9         After Years Global Puma Ambassador LG Mobile A...\n",
              "10        Idek what to do anymore Spain and Portugal bot...\n",
              "11        know it been an amazing World Cup but this is ...\n",
              "12        by our happy virus will be perfect choice Happ...\n",
              "13        Get the best in sports news and information by...\n",
              "14        Just worked out that if England can get past C...\n",
              "15        People getting rightly excited over Mbappe aft...\n",
              "16                             PENALTY SHOOTOUTS IN ONE DAY\n",
              "17        Edinson Cavani for Napoli Games Goals Edinson ...\n",
              "18        Japan have never made it past the last eight s...\n",
              "19        Wonder what the odds were on Messi Ronaldo and...\n",
              "20        Lebron news is cool and all pero let gets back...\n",
              "21        Highly anticipating by to be played at the sta...\n",
              "22        How Do You Control the Ball Lose How Do You Pa...\n",
              "23        Kasper Schmeichel vs Croatia Saves penalty in ...\n",
              "24                It was really difficult for fandom but we\n",
              "25        Mikel John Obi is the only player to have repr...\n",
              "26        PoliticalRumble LIVE LOUD LITUP ON WE ARE GOIN...\n",
              "27                                                 Poweeeer\n",
              "28        Soccer team of British WWI soldiers wearing ga...\n",
              "29        Japan have never made it past the last eight s...\n",
              "                                ...                        \n",
              "529970    According to various reports during Frances on...\n",
              "529971                     Supporters in the upcoming final\n",
              "529972    All players on the winning squad have had thei...\n",
              "529973                 The award winners from an incredible\n",
              "529974    Dear France Congratulations on winning the of ...\n",
              "529975    Dear France Congratulations on winning the of ...\n",
              "529976    are the raining reigning champions Sorry not s...\n",
              "529977    Dear France Congratulations on winning the of ...\n",
              "529978    Dear France Congratulations on winning the of ...\n",
              "529979    Dear France Congratulations on winning the of ...\n",
              "529980    France just won the of its teams players are i...\n",
              "529981                   So proud of the Golden Ball winner\n",
              "529982    You guys voted right Congratulations on being ...\n",
              "529983                 The award winners from an incredible\n",
              "529984    Dear France Congratulations on winning the of ...\n",
              "529985    Ronaldos Hattrick Germany Out In Groups Late W...\n",
              "529986    long time ago very young Griezmann was just as...\n",
              "529987    Dear France Congratulations on winning the of ...\n",
              "529988      Shaku Shaku has won the Give it them Paul Pogba\n",
              "529989                                                Proud\n",
              "529990                   The moment became Highlights https\n",
              "529991                   The moment became Highlights https\n",
              "529992    Dear France Congratulations on winning the of ...\n",
              "529993    Dear France Congratulations on winning the of ...\n",
              "529994              Going to bed the night before the final\n",
              "529995                   France have won the FIFA in Moscow\n",
              "529996    Beyonc JAY performed in blue jersey to celebra...\n",
              "529997    They don say immigrants are ruining France whe...\n",
              "529998                           starts for in todays final\n",
              "529999    Dear France Congratulations on winning the of ...\n",
              "Name: Tweet, Length: 530000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBE0Bf2p12MG",
        "colab_type": "code",
        "colab": {},
        "outputId": "73c06cc2-2762-45ee-d5c2-e9e0fdb30aa3"
      },
      "source": [
        "for row in a:\n",
        "    print(row)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only two goalkeepers have saved three penalties in penalty shoot out Ricardo vs\n",
            "scores the winning penalty to send into the quarter finals where they will face Russia\n",
            "Tonight we have big game\n",
            "We get stronger Turn the music up now We got that power power\n",
            "Only two goalkeepers have saved three penalties in penalty shoot out Ricardo vs\n",
            "We re looking strong going into the knockout stage We caught up with ahead of\n",
            "am happy for winning Especially since you know we colluded and all Russia eliminates Spain after penalty\n",
            "When you see me When we feel the same feeling Power power\n",
            "Kasper Schmeichel takes the final award of the day\n",
            "After Years Global Puma Ambassador LG Mobile Ambassador CocaCola WorldCup Kookmin Bank UNICEF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRD7hV_O12MI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}